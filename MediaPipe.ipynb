{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "열 (80, 100)\n",
      "열 (50, 30, 100)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Mediapipe의 Hands 모듈 초기화\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 동영상 파일 열기\n",
    "input_video_path = \"C:/Users/elena/Downloads/KETI_SL_0000001137.avi\"\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# 새로운 동영상 파일 생성 준비\n",
    "output_video_path = 'output_video.mp4'\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "fps = int(cap.get(5))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "idx = '열'\n",
    "\n",
    "PATH = \"C:/Users/elena/Desktop/data/\"\n",
    "\n",
    "data = []\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()  # 프레임 읽기\n",
    "    if not ret: # 제대로 읽지 못했을 경우 ret=False\n",
    "        break`\n",
    "    \n",
    "    # 프레임을 BGR에서 RGB로 변환\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 손 검출 수행\n",
    "    results = hands.process(rgb_frame)\n",
    "    \n",
    "    if results.multi_hand_landmarks is not None:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            joint = np.zeros((21, 4))\n",
    "            for j, lm in enumerate(hand_landmarks.landmark):\n",
    "                joint[j] = [lm.x, lm.y, lm.z, lm.visibility]\n",
    "            \n",
    "            v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :3] # Parent joint\n",
    "            v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :3] # Child joint\n",
    "            v = v2 - v1 # [20, 3]\n",
    "            # Normalize v\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "            # Get angle using arcos of dot product\n",
    "            angle = np.arccos(np.einsum('nt,nt->n', # Einstein Summation 표기법으로 다차원 배열의 내적 계산 -> arccos값 구해서 angle에 할당\n",
    "                v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], # einsum: 두 개의 벡터 배열 간의 내적 계산\n",
    "                v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]\n",
    "            \n",
    "            angle = np.degrees(angle) # Convert radian to degree\n",
    "    \n",
    "            angle_label = np.array([angle], dtype=np.float32)\n",
    "            angle_label = np.append(angle_label, idx)\n",
    "\n",
    "            d = np.concatenate([joint.flatten(), angle_label])\n",
    "            \n",
    "            data.append(d)\n",
    "\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "        \n",
    "    # 결과를 새로운 동영상에 기록\n",
    "    out.write(frame)\n",
    "\n",
    "data = np.array(data)\n",
    "print(idx, data.shape)\n",
    "np.save('data.npy', data)\n",
    "\n",
    "# seq_length = 30\n",
    "\n",
    "# # 30이라는 사이즈의 윈도우를 가진 100개의 포인트\n",
    "# full_seq_data = []\n",
    "# for seq in range(len(data) - seq_length): # data의 길이에서 seq_length만큼 뺌\n",
    "#     full_seq_data.append(data[seq:seq + seq_length]) # full_seq_data에 data의 제일 뒤 쪽 seq_length만큼의 frame을 append\n",
    "\n",
    "# full_seq_data = np.array(full_seq_data)\n",
    "# print(idx, full_seq_data.shape)\n",
    "# np.save('C:/Users/Elena/Desktop/seq_data.npy', full_seq_data)\n",
    "\n",
    "# 리소스 해제\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.3686419427394867' '0.888746440410614' '1.3251178643258754e-07' ...\n",
      "  '10.508908' '1.8008835' '열']\n",
      " ['0.3841209411621094' '0.8017615079879761' '2.633049689393374e-07' ...\n",
      "  '13.775346' '5.593472' '열']\n",
      " ['0.5735070705413818' '0.8655163049697876' '5.24487617781233e-08' ...\n",
      "  '5.763534' '1.2423095' '열']\n",
      " ...\n",
      " ['0.37256401777267456' '0.7951946258544922' '2.0155064817117818e-07' ...\n",
      "  '9.403677' '1.8946248' '열']\n",
      " ['0.5844031572341919' '0.9408870339393616' '1.3918835861659318e-07' ...\n",
      "  '4.599236' '5.6893225' '열']\n",
      " ['0.34350547194480896' '0.9066401124000549' '8.638599524601887e-08' ...\n",
      "  '9.382911' '1.1706026' '열']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load('data.npy')\n",
    "print(data) # 총 97프레임 중 80프레임 인식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 왼손 오른손 구분해서 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Mediapipe의 Hands 모듈 초기화\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 동영상 파일 열기\n",
    "input_video_path = \"C:/Users/elena/Downloads/KETI_SL_0000001137.avi\"\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# 새로운 동영상 파일 생성 준비\n",
    "output_video_path = 'output_video.mp4'\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "fps = int(cap.get(5))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "idx = '열'\n",
    "\n",
    "left_data = []\n",
    "right_data = []\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()  # 프레임 읽기\n",
    "    if not ret: # 제대로 읽지 못했을 경우 ret=False\n",
    "        break\n",
    "    \n",
    "    # 프레임을 BGR에서 RGB로 변환\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 손 검출 수행\n",
    "    results = hands.process(rgb_frame)\n",
    "    \n",
    "    if results.multi_hand_landmarks is not None:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            joint = np.zeros((21, 4))\n",
    "            for j, lm in enumerate(hand_landmarks.landmark):\n",
    "                joint[j] = [lm.x, lm.y, lm.z, lm.visibility]\n",
    "            \n",
    "            v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :3] # Parent joint\n",
    "            v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :3] # Child joint\n",
    "            v = v2 - v1 # [20, 3]\n",
    "            # Normalize v\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "            # Get angle using arcos of dot product\n",
    "            angle = np.arccos(np.einsum('nt,nt->n', # Einstein Summation 표기법으로 다차원 배열의 내적 계산 -> arccos값 구해서 angle에 할당\n",
    "                v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], # einsum: 두 개의 벡터 배열 간의 내적 계산\n",
    "                v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]\n",
    "            \n",
    "            angle = np.degrees(angle) # Convert radian to degree\n",
    "    \n",
    "            angle_label = np.array([angle], dtype=np.float32)\n",
    "            angle_label = np.append(angle_label, idx)\n",
    "\n",
    "            d = np.concatenate([joint.flatten(), angle_label])\n",
    "            \n",
    "            is_left_hand = results.multi_handedness[0].classification[0].label == \"Left\"\n",
    "\n",
    "            if is_left_hand:\n",
    "                left_data.append(d)\n",
    "            else:\n",
    "                right_data.append(d)\n",
    "            \n",
    "\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "        \n",
    "    # 결과를 새로운 동영상에 기록\n",
    "    out.write(frame)\n",
    "\n",
    "left_data = np.array(left_data)\n",
    "right_data = np.array(right_data)\n",
    "np.save('left_data.npy', left_data)\n",
    "np.save('right_data.npy', right_data)\n",
    "# 리소스 해제\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100)\n",
      "(16, 100)\n"
     ]
    }
   ],
   "source": [
    "left = np.load('left_data.npy')\n",
    "right = np.load('right_data.npy')\n",
    "\n",
    "print(left.shape)\n",
    "print(right.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WeHigher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
